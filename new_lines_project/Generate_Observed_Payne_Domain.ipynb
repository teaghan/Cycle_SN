{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the \"observed\" dataset\n",
    "\n",
    "Here we will generate training, validation, and test sets that will be used as our \"observed\" dataset. These will consist of spectra generated using The Payne with noise added afterwards. These spectra are going to contain the entire line list, as opposed to the \"synthetic\" dataset, which will have particular lines masked out (ie. set to the continuum value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "%matplotlib inline \n",
    "\n",
    "from The_Payne.utils import read_in_neural_network\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from network import build_emulator\n",
    "\n",
    "data_dir = '../data/'\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build The Payne network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Payne pre-trained weights\n",
    "emulator_coeffs = read_in_neural_network()\n",
    "\n",
    "# Build emulator and assign layer weights\n",
    "emulator, y_min, y_max = build_emulator(emulator_coeffs=emulator_coeffs, use_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Payne labels that were used to train the model initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order:\n",
    "\n",
    "# [Teff, Logg, Vturb [km/s],\n",
    "# [C/H], [N/H], [O/H], [Na/H], [Mg/H],\\\n",
    "# [Al/H], [Si/H], [P/H], [S/H], [K/H],\\\n",
    "# [Ca/H], [Ti/H], [V/H], [Cr/H], [Mn/H],\\\n",
    "# [Fe/H], [Co/H], [Ni/H], [Cu/H], [Ge/H],\\\n",
    "# C12/C13, Vmacro [km/s]\n",
    "labels_payne = np.load(data_dir+'mock_all_spectra_no_noise_resample_prior_large.npz')['labels'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the labels for our training, validation, and test sets. To do this, we will take the initial labels that were loaded above and perturb them slightly to add some randomness to our datasets. Ideally, we would draw these labels randomly from a large distribution, however, the Payne can only produce spectra accurately that are within the limits of its training set. Therefore, we must stay close to this initial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of Payne spectra to create for each dataset\n",
    "num_tr = 50000\n",
    "num_val = 2000\n",
    "num_te = 2000\n",
    "\n",
    "# Perturb the payne labels within a range to create our training, cv, and test sets.\n",
    "# These perturbations are in the same order as the labels.\n",
    "perturbations = [100., 0.1, 0.2, *np.repeat(0.1, 20), 5., 2.]\n",
    "\n",
    "# Create sets by randomly selecting from original Payne training set\n",
    "payne_tr_labels = np.copy(labels_payne[np.random.randint(len(labels_payne), size=num_tr)])\n",
    "payne_val_labels = np.copy(labels_payne[np.random.randint(len(labels_payne), size=num_val)])\n",
    "payne_te_labels = np.copy(labels_payne[np.random.randint(len(labels_payne), size=num_te)])\n",
    "\n",
    "# Apply random perturbations within the above limits\n",
    "payne_tr_labels += np.array([np.random.uniform(-1*p, p, size=num_tr) for p in perturbations]).T\n",
    "payne_val_labels += np.array([np.random.uniform(-1*p, p, size=num_val) for p in perturbations]).T\n",
    "payne_te_labels += np.array([np.random.uniform(-1*p, p, size=num_te) for p in perturbations]).T\n",
    "\n",
    "# Correct the minimum Vturb, C12/C13, and Vmacro values\n",
    "for i in [2,23,24]:\n",
    "    payne_tr_labels[payne_tr_labels[:,i]<np.min(labels_payne[:,i]),i] = np.min(labels_payne[:,i])\n",
    "    payne_val_labels[payne_val_labels[:,i]<np.min(labels_payne[:,i]),i] = np.min(labels_payne[:,i])\n",
    "    payne_te_labels[payne_te_labels[:,i]<np.min(labels_payne[:,i]),i] = np.min(labels_payne[:,i])\n",
    "    \n",
    "# Set Vmacro for the first 1000 samples in the validation and test sets to 15km/s.\n",
    "# This will allow us to test our split latent-space method by generating matching spectra in the \n",
    "# \"synthetic\" domain to do direct comparisons with.\n",
    "payne_val_labels[:1000,24] = 15.\n",
    "payne_te_labels[:1000,24] = 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the Payne model to produce the spectra from the labels created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spectra(emulator, y, x_min, x_max):\n",
    "    # Turn labels into pytorch variable\n",
    "    y = Variable(torch.Tensor(y.astype(np.float32)))\n",
    "    # Scale the labels the same as it was done during the training of the Payne\n",
    "    scaled_labels = (y-y_min)/(y_max-y_min) - 0.5\n",
    "    # Return predicted spectra\n",
    "    return emulator(scaled_labels).data.numpy()\n",
    "\n",
    "payne_tr_specs = predict_spectra(emulator, payne_tr_labels, y_min, y_max)\n",
    "payne_val_specs = predict_spectra(emulator, payne_val_labels, y_min, y_max)\n",
    "payne_te_specs = predict_spectra(emulator, payne_te_labels, y_min, y_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some noise to each spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximiate limits to the noise added. A noise factor or 0.05 will give that \n",
    "# particular pixel a S/N of 1/0.05 = 20.\n",
    "max_noise = 0.05\n",
    "min_noise = 0.001\n",
    "\n",
    "# Create a noise factor for each spectrum\n",
    "noise_factor_tr = np.random.uniform(low=min_noise, high=max_noise, size=(len(payne_tr_specs),1))\n",
    "noise_factor_val = np.random.uniform(low=min_noise, high=max_noise, size=(len(payne_val_specs),1))\n",
    "noise_factor_te = np.random.uniform(low=min_noise, high=max_noise, size=(len(payne_te_specs),1))\n",
    "\n",
    "# Generate noise spectra that will be added to the spectra\n",
    "spec_err_tr = noise_factor_tr*np.random.uniform(low=0.1, high=1., size=payne_tr_specs.shape)\n",
    "spec_err_val = noise_factor_val*np.random.uniform(low=0.1, high=1., size=payne_val_specs.shape)\n",
    "spec_err_te = noise_factor_te*np.random.uniform(low=0.1, high=1., size=payne_te_specs.shape)\n",
    "\n",
    "# Add noise\n",
    "payne_tr_specs += spec_err_tr\n",
    "payne_val_specs += spec_err_val\n",
    "payne_te_specs += spec_err_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an idea of the approximate S/N limits, we will calculate the S/N for the cross-validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The S/N of our observed dataset ranges from approximately 49 to 2518.\n"
     ]
    }
   ],
   "source": [
    "snr_val = np.mean(payne_val_specs/spec_err_val, axis=1)\n",
    "print('The S/N of our observed dataset ranges from approximately %0.0f to %0.0f.' % (np.min(snr_val), np.max(snr_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data to an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished.\n"
     ]
    }
   ],
   "source": [
    "savename_synth = data_dir+'PAYNE_NL.h5'\n",
    "\n",
    "with h5py.File(savename_synth, \"w\") as f:    \n",
    "    \n",
    "    # Datasets for h5 file\n",
    "    spec_tr_ds = f.create_dataset('PAYNE spectrum train', \n",
    "                                  payne_tr_specs.shape, dtype=\"f\")\n",
    "    spec_val_ds = f.create_dataset('PAYNE spectrum val', \n",
    "                                  payne_val_specs.shape, dtype=\"f\")\n",
    "    spec_te_ds = f.create_dataset('PAYNE spectrum test', \n",
    "                                  payne_te_specs.shape, dtype=\"f\")\n",
    "    spec_err_tr_ds = f.create_dataset('PAYNE error_spectrum train', \n",
    "                                  spec_err_tr.shape, dtype=\"f\")\n",
    "    spec_err_val_ds = f.create_dataset('PAYNE error_spectrum val', \n",
    "                                  spec_err_val.shape, dtype=\"f\")\n",
    "    spec_err_te_ds = f.create_dataset('PAYNE error_spectrum test', \n",
    "                                  spec_err_te.shape, dtype=\"f\")\n",
    "    labels_tr_ds = f.create_dataset('PAYNE labels train', \n",
    "                                  payne_tr_labels.shape, dtype=\"f\")\n",
    "    labels_val_ds = f.create_dataset('PAYNE labels val', \n",
    "                                  payne_val_labels.shape, dtype=\"f\")\n",
    "    labels_te_ds = f.create_dataset('PAYNE labels test', \n",
    "                                  payne_te_labels.shape, dtype=\"f\")\n",
    "    \n",
    "    # Save data\n",
    "    spec_tr_ds[:] = payne_tr_specs\n",
    "    spec_val_ds[:] = payne_val_specs\n",
    "    spec_te_ds[:] = payne_te_specs\n",
    "    spec_err_tr_ds[:] = spec_err_tr\n",
    "    spec_err_val_ds[:] = spec_err_val\n",
    "    spec_err_te_ds[:] = spec_err_te\n",
    "    labels_tr_ds[:] = payne_tr_labels\n",
    "    labels_val_ds[:] = payne_val_labels\n",
    "    labels_te_ds[:] = payne_te_labels\n",
    "            \n",
    "print('finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, collect the mean and standard deviation of the synthetic spectra for normalizing the inputs to the Cycle-GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_payne = np.load(data_dir+'mock_all_spectra_no_noise_resample_prior_large.npz')['spectra']\n",
    "np.save(data_dir+'mean_and_std_PAYNE_specs.npy', np.array([np.mean(spectra_payne),np.std(spectra_payne)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
